## 五、可视化界面

### 5.1 Pyside6开发

* 按照视频教程安装环境并绘制页面即可，保存为【main_window.ui】文件:

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/36df4a7d-6844-4f16-b5dc-76740c3b7e08)


* 在vsCode中右键编译ui文件：

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/45419893-f535-47f9-b8ae-b448243e9ddd)


* 编写【base_ui.py】程序以实现可视化界面显示：

  * ```python
    import sys
    import torch
    import cv2
    from PySide6.QtWidgets import QMainWindow, QApplication, QFileDialog
    from PySide6.QtGui import QPixmap, QImage   #显示图片的插件
    from PySide6.QtCore import QTimer
    
    from main_window_ui import Ui_MainWindow
    
    def convert2QImage(img):
        height, width, channel = img.shape
        return QImage(img, width, height, width * channel, QImage.Format_RGB888)
    
    class MainWindow(QMainWindow, Ui_MainWindow):
        def __init__(self):
            super(MainWindow, self).__init__()
            self.setupUi(self)
            # Model
            self.model = torch.hub.load("./", "custom", path="runs/train/exp9/weights/best.pt", source="local")
            # Timer
            self.timer = QTimer()
            self.timer.setInterval(1)
            self.video = None
            self.bind_slots()
    
        def image_pred(self, file_path):
            # inference
            results = self.model(file_path)
            image = results.render()[0]
            return convert2QImage(image)
        
        def open_image(self):
            self.timer.stop()
            file_path = QFileDialog.getOpenFileName(self, dir="./datasets/images/train", filter="*.jpg;*.png;*.jpeg")
            if file_path[0]:
                file_path = file_path[0]
                qimage = self.image_pred(file_path)
                self.input.setPixmap(QPixmap(file_path))
                self.output.setPixmap(QPixmap.fromImage(qimage))
    
        def video_pred(self):
            ret, frame = self.video.read()
            if not ret:
                    self.timer.stop()
            else:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                self.input.setPixmap(QPixmap.fromImage(convert2QImage(frame)))
                # inference
                results = self.model(frame)
                image = results.render()[0]
                self.output.setPixmap(QPixmap.fromImage(convert2QImage(image)))
        
        def open_video(self):
            print("clicked det_video")
            file_path = QFileDialog.getOpenFileName(self, dir="./datasets", filter="*.mp4")
            if file_path[0]:
                file_path = file_path[0]
            self.video = cv2.VideoCapture(file_path)
            self.timer.start()
                
        def bind_slots(self):
            self.det_image.clicked.connect(self.open_image)
            self.det_video.clicked.connect(self.open_video)
            self.timer.timeout.connect(self.video_pred)
    
    if __name__ == "__main__":
        app = QApplication(sys.argv)
    
        window = MainWindow()
        window.show()
        
        app.exec()
    ```

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/7fb8ce32-d47a-40e8-9e10-eb1b7c4def64)


  

  

  

  
