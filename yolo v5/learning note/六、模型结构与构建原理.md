### 6.1 ç»“æ„å®šä¹‰

* æ–‡ä»¶ä½ç½®ï¼šmodels-yolov5.yaml

* å‚æ•°ä»‹ç»ï¼š

  * ```python
    # Parameters
    nc: 80  # number of classes åˆ†ç±»ç±»åˆ«
    depth_multiple: 0.33  # model depth multiple æ·±åº¦ç¼©æ”¾ç³»æ•°ï¼Œå½±å“Backboneä¸­çš„numberé‡å¤æµ‹æ•°ï¼Œä¸å…¶ç›¸ä¹˜ï¼Œä¸1å¯¹æ¯”å»æœ€å¤§å€¼
    width_multiple: 0.50  # layer channel multiple å¹¿åº¦ç¼©æ”¾ç³»æ•°ï¼Œå½±å“è¾“å‡ºé€šé“æ•°ï¼ˆargsä¸­ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰
    anchors: # é”šæ¡†ï¼ˆé”šå®šæ¡†ï¼‰ï¼šä¸‰ä¸ªç‰¹å¾å›¾ï¼Œæ¯ä¸ªç‰¹å¾å›¾ä¸Šæœ‰ä¸‰ç»„é”šæ¡†
      - [10,13, 16,30, 33,23]  # P3/8
      - [30,61, 62,45, 59,119]  # P4/16
      - [116,90, 156,198, 373,326]  # P5/32
    ```

  * ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/3862caa95dd343f090808690e2648e23.png)

  * Backboneï¼š

    * ```python
      # YOLOv5 v6.0 backbone
      backbone:
        # [from, number, module, args] [ä»å“ªæ¥ï¼ˆ-1å°±æ˜¯ä¸Šä¸€å±‚ï¼‰ï¼Œå½“å‰æ¨¡å—é‡å¤å‡ æ¬¡ï¼Œå…·ä½“ç”¨çš„å“ªä¸ªæ¨¡å—ï¼Œå®ä¾‹åŒ–æ¨¡å—éœ€è¦å­˜å…¥çš„å‚æ•°]
        [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2 ç½‘ç»œç¼–å·-å·ç§¯ç¼–å·/åŸå§‹å›¾åƒç¼©æ”¾å€æ•°
         [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
         [-1, 3, C3, [128]],
         [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
         [-1, 6, C3, [256]],
         [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
         [-1, 9, C3, [512]],
         [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
         [-1, 3, C3, [1024]],
         [-1, 1, SPPF, [1024, 5]],  # 9
        ]
      ```

  * headï¼š

    * ```python
      # YOLOv5 v6.0 head
      head:
        [[-1, 1, Conv, [512, 1, 1]],
         [-1, 1, nn.Upsample, [None, 2, 'nearest']],
         [[-1, 6], 1, Concat, [1]],  # cat backbone P4
         [-1, 3, C3, [512, False]],  # 13
      
         [-1, 1, Conv, [256, 1, 1]],
         [-1, 1, nn.Upsample, [None, 2, 'nearest']],
         [[-1, 4], 1, Concat, [1]],  # cat backbone P3
         [-1, 3, C3, [256, False]],  # 17 (P3/8-small) 8å€ä¸‹é‡‡æ ·ç”¨äºæ£€æµ‹å°å‹ç‰©ä½“
      
         [-1, 1, Conv, [256, 3, 2]],
         [[-1, 14], 1, Concat, [1]],  # cat head P4
         [-1, 3, C3, [512, False]],  # 20 (P4/16-medium) 16å€ä¸‹é‡‡æ ·ç”¨äºæ£€æµ‹ä¸­ç­‰ç‰©ä½“
      
         [-1, 1, Conv, [512, 3, 2]],
         [[-1, 10], 1, Concat, [1]],  # cat head P5
         [-1, 3, C3, [1024, False]],  # 23 (P5/32-large) 32å€ä¸‹é‡‡ç”¨ç”¨äºæ£€æµ‹å¤§å‹ç‰©ä½“
      
         [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
        ]
      ```

### 6.2 ä¿®æ”¹ç½‘ç»œç»“æ„

#### 6.1.2 åŠ å…¥C2f

ï¼ˆ1ï¼‰ä¸‹è½½yolo v8ï¼š

* [Releases Â· ultralytics/ultralytics (github.com)](https://github.com/ultralytics/ultralytics)
* C2fæ‰€åœ¨æ–‡ä»¶ä½ç½®ï¼š
  * "E:\AI\Package\ultralytics-main\ultralytics-main\ultralytics\nn\modules\block.py"

ï¼ˆ2ï¼‰åŠ å…¥æ–°å¢ç½‘ç»œç»“æ„ï¼š

* ç›®æ ‡ä½ç½®ï¼šmodels/commons.py
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/2ae8070a-7051-42fc-ae85-eee83ae6e16f)

* C2fä¸­çš„Bottleneckå¤šäº†kå‚æ•°ï¼Œå› æ­¤éœ€è¦æ·»åŠ 
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/dc1e1567-d1ed-47d2-9b99-c91e2502ba9d)

* åŠ å…¥C2få‰ç¼€
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/f1f13d24-b605-4093-a65e-6485e48fa7f6)


ï¼ˆ3ï¼‰è®¾å®šç½‘ç»œç»“æ„çš„ä¼ å‚ç»†èŠ‚

* ç›®æ ‡ä½ç½®ï¼šmodels/yolo.py
* åœ¨yolo.pyä¸­åŠ å…¥C2fçš„æ¥å£ï¼Œä»¥ä¸ºC2få’ŒC3ä¼ å‚ä¸€è‡´ï¼Œæ‰€ä»¥å¯ä»¥åœ¨parse_modelä»£ç ä¸­æœ‰C3çš„åœ°æ–¹åŠ å…¥å³å¯ï¼š
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/47f71fb3-35c3-4eb6-91e0-769a8eb397ed)


ï¼ˆ4ï¼‰ä¿®æ”¹ç°æœ‰æ¨¡å‹ç»“æ„é…ç½®æ–‡ä»¶

* ç›®æ ‡ä½ç½®ï¼šmodels/yolov5*.yaml
* å¤åˆ¶æ–‡ä»¶ï¼š
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/b5d16adb-3103-43a1-b780-b005865562e3)

* å°†backboneä¸­çš„C3æ”¹ä¸ºC2f
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/77b431a1-df33-4929-9307-0cf43f7a1b77)


ï¼ˆ5ï¼‰è®­ç»ƒæ—¶æŒ‡å®šæ¨¡å‹ç»“æ„é…ç½®æ–‡ä»¶

* ç›®æ ‡ä½ç½®ï¼štrain.py

* ä¿®æ”¹cfgå‚æ•°ï¼š

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/47cb6425-0ffa-4638-8dcf-77565bb6dd40)


  * ```python
    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')
    #åŠ å…¥è‡ªå·±å»ºç«‹çš„yamlæ–‡ä»¶ï¼š
    parser.add_argument('--cfg', type=str, default=ROOT / 'models/yolov5s-c2f.yaml', help='model.yaml path')
    ```

* è®­ç»ƒï¼š

  * (yolov5) E:\AI\Package\yolov5-7.0>python train.py
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/3f0fc353-c477-4d0a-b04b-91a8c3c6ba20)

    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/d7041d5b-59ec-4862-b996-f81b5d448efe)


#### 6.2.2 å¼•å…¥SEæ³¨æ„åŠ›æœºåˆ¶

ï¼ˆ1ï¼‰å€Ÿé‰´ä»£ç ï¼š

* [ZhugeKongan/Attention-mechanism-implementation: Self-attentionã€Non-localã€SEã€SKã€CBAMã€DANet (github.com)](https://github.com/ZhugeKongan/Attention-mechanism-implementation)

ï¼ˆ2ï¼‰æ–‡ä»¶ä½ç½®ï¼š

* "E:\AI\Package\Attention-mechanism-implementation-main\models\SE_block.py"

ï¼ˆ3ï¼‰åŠ å…¥æ–°çš„ç½‘ç»œç»“æ„ï¼š

* ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/81bb9285-7425-46d7-abac-2990d60176bb)

* ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/98386f50-e6c7-4c17-a3ff-75ce12dc18f9)

ï¼ˆ4ï¼‰ä¿®æ”¹ç°æœ‰çš„æ¨¡å‹é…ç½®æ–‡ä»¶ï¼š

* ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/eaee1593-6192-4b3c-aa4c-96de4716b2c4)


* ğŸ“Œ**<u>å¼•å…¥å½¢å±‚éœ€è¦æ³¨æ„ç¼–å·</u>**ï¼Œå› ä¸ºåœ¨Backboneä¸­å¤šåŠ äº†ä¸€å±‚SEï¼Œå› æ­¤æ­¤æ—¶SEæ˜¯ç¬¬10å±‚ï¼Œé‚£ä¹ˆåé¢Headä¸­å¤§äº10å±‚çš„éƒ½éœ€è¦åŠ 1å±‚ï¼š

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/c98c5e78-8fa1-472b-9305-08624c4c1e0c)


  * ```python
    # YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
    
    # Parameters
    nc: 80  # number of classes
    depth_multiple: 0.33  # model depth multiple
    width_multiple: 0.50  # layer channel multiple
    anchors:
      - [10,13, 16,30, 33,23]  # P3/8
      - [30,61, 62,45, 59,119]  # P4/16
      - [116,90, 156,198, 373,326]  # P5/32
    
    # YOLOv5 v6.0 backbone
    backbone:
      # [from, number, module, args]
      [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
       [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
       [-1, 3, C3, [128]],
       [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
       [-1, 6, C3, [256]],
       [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
       [-1, 9, C3, [512]],
       [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
       [-1, 3, C3, [1024]],
       [-1, 1, SPPF, [1024, 5]],  # 9
       [-1, 1, SE, [1024, 2]] #10
      ]
    
    # YOLOv5 v6.0 head
    head:
      [[-1, 1, Conv, [512, 1, 1]],
       [-1, 1, nn.Upsample, [None, 2, 'nearest']],
       [[-1, 6], 1, Concat, [1]],  # cat backbone P4
       [-1, 3, C3, [512, False]],  # 13-14
    
       [-1, 1, Conv, [256, 1, 1]],
       [-1, 1, nn.Upsample, [None, 2, 'nearest']],
       [[-1, 4], 1, Concat, [1]],  # cat backbone P3
       [-1, 3, C3, [256, False]],  # 17-18 (P3/8-small)
    
       [-1, 1, Conv, [256, 3, 2]],
       [[-1, 15], 1, Concat, [1]],  # cat head P4
       [-1, 3, C3, [512, False]],  # 20-21 (P4/16-medium)
    
       [-1, 1, Conv, [512, 3, 2]],
       [[-1, 11], 1, Concat, [1]],  # cat head P5
       [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)
    
       [[18, 21, 24], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
      ]
    ```

ï¼ˆ5ï¼‰è®¾å®šç½‘ç»œç»“æ„çš„ä¼ å‚ç»†èŠ‚ï¼š

* **å½“æ–°çš„è‡ªå®šä¹‰æ¨¡å—ä¸­å­˜åœ¨è¾“å…¥è¾“å‡ºç»´åº¦æ—¶ï¼Œè¦ä½¿ç”¨gwè°ƒæ•´è¾“å‡ºç»´åº¦ï¼**

* åœ¨yolo.pyä¸­çš„parse_modle()å‡½æ•°ä¸­åŠ å…¥å¯¹SEçš„å¤„ç†ï¼š

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/1d6cb241-a466-4330-93f8-9f8faff71c12)


  * ```python
    elif m is SE:
        c1 = ch[f]  #c1ç­‰äºä¸Šä¸€å±‚
        c2 = args[0] #c1å’Œc2ä¸€æ ·
        if c2 != no:  # if not output
            c2 = make_divisible(c2 * gw, 8)
        args = [c1, *args[1:]]
    ```

ï¼ˆ6ï¼‰è®­ç»ƒæ—¶æŒ‡å®šæ¨¡å‹ç»“æ„é…ç½®æ–‡ä»¶

* ç›®æ ‡ä½ç½®ï¼štrain.py

* ä¿®æ”¹cfgå‚æ•°ï¼š

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/6c422abf-85b0-432c-9f98-10bf8c72aaf5)


  * ```python
    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')
    #åŠ å…¥è‡ªå·±å»ºç«‹çš„yamlæ–‡ä»¶ï¼š
    parser.add_argument('--cfg', type=str, default=ROOT / 'models/yolov5s-se.yaml', help='model.yaml path')
    ```

* è®­ç»ƒï¼š

  * (yolov5) E:\AI\Package\yolov5-7.0>python train.py
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/0e549a42-3f5f-4c47-8f77-fc7f0e348901)

    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/ba97f865-5a7e-4988-a153-08384761db46)
   
#### 6.2.3 æ›¿æ¢ä¸»å¹²ç½‘ç»œMobileNet

ï¼ˆ1ï¼‰å€Ÿé‰´ä»£ç ï¼š

* torchvision

ï¼ˆ2ï¼‰æ–‡ä»¶ä½ç½®ï¼š

* æ–°å»ºæ–‡ä»¶ã€demo.ipynbã€‘ï¼ŒåŠ è½½mobilenetç½‘ç»œï¼š
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/1d8a493a-8517-4f3c-96b0-58bc4163efb1)

* å®‰è£…torchinfoï¼š
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/83e3f097-f946-4df0-ada8-e69a6b249b56)


* å¯¼å…¥torchinfoä¸­çš„summaryå·¥å…·æŸ¥çœ‹æ¨¡å‹ç»“æ„ï¼š
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/74ea0b0b-4ab2-4221-a21e-3dfc81579ec6)

  * ä¸»è¦ç”¨çš„æ˜¯Sequentialæ¨¡å—ï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/d86e00be-f199-478e-b054-776cf145b762)

* æ‰“å¼€featuresç‰¹å¾æå–æ¨¡å—ï¼š
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/19344bd7-5398-4ab9-90a5-2a4f1ec8fedd)

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/42b580ff-96bd-4b61-b281-bd9325ce0b11)



ï¼ˆ3ï¼‰åŠ å…¥æ–°çš„ç½‘ç»œç»“æ„ï¼š

* é¦–å…ˆæˆ‘ä»¬è¦åˆ†ææ¨¡å‹è¾“å‡ºçš„å°ã€ä¸­ã€å¤§ä¸‰ä¸ªå°ºå¯¸ç½‘ç»œä½ç½®ï¼š

  * 8å€ä¸‹é‡‡æ ·ï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/ef279a9d-de68-4fd6-8e52-c77389480813)

  * 16å€ä¸‹é‡‡æ ·ï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/d237b8b7-8d4c-4159-9680-59fb4fd65ffe)

  * 32å€ä¸‹é‡‡æ ·ï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/5731a11c-8816-4c1d-bdaf-93752dc8adf4)


* ä½¿ç”¨featureæŒ‡ä»¤æŸ¥çœ‹æ¨¡å‹ä¸‰ä¸ªéƒ¨åˆ†çš„ç½‘ç»œç»“æ„ï¼š

  * ```python
    model.features[:4]
    model.features[4:9]
    model.features[9:]
    ```

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/300ddb62-5e93-481f-9d2d-291f10588ab2)


* åœ¨ã€common.pyã€‘ä¸­åŠ å…¥MobileNetç±»çš„å®šä¹‰ï¼š

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/af00fa0c-7fe4-4e40-bb75-6da251a2a771)


  * ```python
    import torchvision.models as models
    
    
    class MobileNetV3(nn.Module):
        def __init__(self, slice):
            super(MobileNetV3, self).__init__()
            self.model = None
            if slice == 1:
                self.model = models.mobilenet_v3_small(pretrained=True).features[:4]
            elif slice == 2:
                self.model = models.mobilenet_v3_small(pretrained=True).features[4:9]
            else:
                self.model = models.mobilenet_v3_small(pretrained=True).features[9:] 
    
        def forward(self, x):
            return self.model
    ```

* åœ¨ã€yolov5s-mobilenet.yamlã€‘ä¸­ä¿®æ”¹æ¨¡å‹ç»“æ„ï¼š

  * ```python
    # YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
    
    # Parameters
    nc: 80  # number of classes
    depth_multiple: 0.33  # model depth multiple
    width_multiple: 0.50  # layer channel multiple
    anchors:
      - [10,13, 16,30, 33,23]  # P3/8
      - [30,61, 62,45, 59,119]  # P4/16
      - [116,90, 156,198, 373,326]  # P5/32
    
    # YOLOv5 v6.0 backbone
    backbone:
      # [from, number, module, args]
      [
      #  [-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
      #  [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
      #  [-1, 3, C3, [128]],
      #  [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
      #  [-1, 6, C3, [256]],
      #  [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
      #  [-1, 9, C3, [512]],
      #  [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
      #  [-1, 3, C3, [1024]],
      #  [-1, 1, SPPF, [1024, 5]],  # 9
       [-1, 1, MobileNetV3, [24, 1]],     # 0-P3/8  80*80  # [24, 1]è¡¨ç¤º[è¾“å‡ºé€šé“æ•°ï¼Œ åˆ‡ç‰‡æ ‡å·]
       [-1, 1, MobileNetV3, [48, 2]],     # 1-P4/16  40*40
       [-1, 1, MobileNetV3, [576, 3]]     # 2-P5/32  20*20
      ]
    
    # YOLOv5 v6.0 head
    head:
      [[-1, 1, Conv, [512, 1, 1]],  # 3-10
       [-1, 1, nn.Upsample, [None, 2, 'nearest']],  # 4-11
       [[-1, 1], 1, Concat, [1]],  # 5-12 cat backbone P4(#1)     # 40 * 40 éœ€è¦å’ŒBackboneä¸­çš„ç›¸åŒå°ºå¯¸ç½‘ç»œå±‚æ‹¼æ¥
       [-1, 3, C3, [512, False]],  # 6-13
    
       [-1, 1, Conv, [256, 1, 1]], # 7-14
       [-1, 1, nn.Upsample, [None, 2, 'nearest']], # 8-15
       [[-1, 0], 1, Concat, [1]],  # 9-16 cat backbone P3(#0)     # 80 * 80
       [-1, 3, C3, [256, False]],  # 10-17 (P3/8-small)
    
       [-1, 1, Conv, [256, 3, 2]], # 11-18
       [[-1, 7], 1, Concat, [1]],  # 12-19 cat head P4(#7)        # 40 * 40
       [-1, 3, C3, [512, False]],  # 13-20 (P4/16-medium)
    
       [-1, 1, Conv, [512, 3, 2]], # 14-21
       [[-1, 3], 1, Concat, [1]],  # 15-22 cat head P5(#3)        # 20 * 20
       [-1, 3, C3, [1024, False]],  # 16-23 (P5/32-large)
    
       [[10, 13, 16], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
      ]
    ```

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/03a77128-e01d-41d5-b30f-8473a11aaade)


* åœ¨ã€yolo.pyã€‘ä¸­è¿›è¡Œæ³¨å†Œï¼š

  * ```python
    elif m is MobileNetV3:
        c2 = args[0]
        args = args[1:]
    ```

  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/fe6be7ea-bc6f-4ea2-bad0-efa5710e68bb)


* ã€è®­ç»ƒã€‘è¿è¡Œã€train.pyã€‘ï¼š

  * åŸå§‹è®­ç»ƒç»“æœï¼š
    * ![image-20240318175102418](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240318175102418.png)
  * æ”¹è¿›åçš„è®­ç»ƒç»“æœï¼š
    * æŠ¥é”™ï¼š
      * TypeError: conv2d(): argument 'input' (position 1) must be Tensor, not Sequential
        * ![image-20240318180904020](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240318180904020.png)
      * åŸå› ï¼šåœ¨ã€common.pyã€‘æ–‡ä»¶ä¸­è¿”å›çš„å‚æ•°åº”è¯¥æ˜¯self.model(x)ï¼Œè€Œä¸æ˜¯self.modelï¼š
        * ![image-20240318180834131](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240318180834131.png)
    * æˆåŠŸç»“æœï¼š
      * ![image-20240318181618138](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240318181618138.png)
      * å±‚æ•°å˜å¤šï¼Œä½†æ˜¯å‚æ•°é‡ç›¸è¾ƒäºä¹‹å‰çš„ä¸‹é™è¿‘50%ã€‚







