## å››ã€TensorRTåŸºç¡€å…¥é—¨

### 4.1 æ¨¡å‹éƒ¨ç½²çš„åŸºç¡€çŸ¥è¯†

#### 4.1.1 FLOPS ä¸ TOPS

ç†è§£ FLOPS å’Œ TOPS æ˜¯ä»€ä¹ˆï¼ŒCPU/GPU ä¸­çš„è®¡ç®— FLOPS/TOPS çš„å…¬å¼ï¼Œä»¥åŠCUDA Core å’Œ Tensor Core çš„åŒºåˆ«

##### ï¼ˆ1ï¼‰ç›¸å…³æ¦‚å¿µ

* 1ã€FLOPS
  * æŒ‡çš„æ˜¯ä¸€ç§’é’Ÿå¯ä»¥å¤„ç†çš„æµ®åŠ¨å°æ•°ç‚¹è¿ç®—æ¬¡æ•°
  * æ˜¯è¡¡é‡è®¡ç®—æœºç¡¬ä»¶æ€§èƒ½ã€è®¡ç®—èƒ½åŠ›çš„ä¸€ä¸ªå•ä½
  * å¸¸è§çš„FLOPSï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/2b972a04-baff-49a0-beb9-b269279abfbc)




* 2ã€TOPS
  * æŒ‡çš„æ˜¯ä¸€ç§’é’Ÿå¯ä»¥å¤„ç†çš„æ•´å‹è¿ç®—æ¬¡æ•°
  * æ˜¯è¡¡é‡è®¡ç®—æœºç¡¬ä»¶æ€§èƒ½ã€è®¡ç®—èƒ½åŠ›çš„ä¸€ä¸ªå•ä½
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/a83ca1b7-2b9f-4756-b05f-9ec072b1dbdf)




* 3ã€FLOPs
  * æ˜¯è¡¡é‡æ¨¡å‹å¤§å°çš„ä¸€ä¸ªæŒ‡æ ‡ï¼Œå¤§å®¶åœ¨CVPRçš„paperæˆ–è€…Githubé‡Œç»å¸¸èƒ½å¤Ÿçœ‹åˆ°çš„å°±æ˜¯è¿™ä¸ªä¿¡æ¯



##### ï¼ˆ2ï¼‰FLOPS åœ¨ CPU ä¸­æ˜¯å¦‚ä½•è®¡ç®—çš„

* å…¬å¼ï¼š
  * FLOPS = é¢‘ç‡ * coreæ•°é‡ * æ¯ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„ FLOPS
    * é¢‘ç‡ï¼šæ—¶é’Ÿé¢‘ç‡
    * Coreï¼šç¡¬ä»¶æ ¸æ•°é‡
    * æ¯ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„ FLOPS
* ç¤ºä¾‹ï¼š
  * ï¼ˆIntel i7 Haswellæ¶æ„ï¼‰8æ ¸ï¼Œé¢‘ç‡3.0GHzï¼š
    * FLOPSåœ¨åŒç²¾åº¦çš„æ—¶å€™ï¼š
      * 3.0 * 10^9Hz * 8 core * 16 FLOPS/clk = 0.38 TFLOPS
    * FLOPSåœ¨å•ç²¾åº¦çš„æ—¶å€™ï¼š
      * 3.0 * 10^9Hz * 8 core * 32 FLOPS/clk = 0.76 TFLOPS
    * è®¡ç®—ç»†èŠ‚ï¼š
      * [1] åœ¨è¯¥èŠ¯ç‰‡å†…éƒ¨æœ‰2ä¸ªFMAï¼Œä»¥åŠæ”¯æŒAVX-256æŒ‡ä»¤é›†ï¼š
        * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/068b07a3-452e-47f9-864d-6054d98dff21)

      * [2] FMAæ˜¯ä¹˜åŠ è¿ç®—æ··åˆçš„ä¸€ç§æ–¹æ³•
        * æ²¡æœ‰FMAï¼Œä¹˜æ³•åŠ æ³•åˆ†å¼€ç®—
          * è®¡ç®—D = A * B + Céœ€è¦ä¸¤ä¸ªæ—¶é’Ÿå‘¨æœŸ
          * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/2616d6d4-04ca-40a3-bf13-916302722829)

        * æœ‰FMAï¼Œä¹˜æ³•åŠ æ³•ä¸€èµ·ç®—
          * è®¡ç®—D = A * B + Céœ€è¦ä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸ
          * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/3dfba1d5-d511-470a-b5f3-6aaf90490040)

      * [3] AVX-256 æŒ‡ä»¤é›†ä¸­ä¸€ä¸ªDoubleæŒ‡ä»¤èƒ½å­˜2ä¸ªFloatæŒ‡ä»¤ï¼Œæ‰€ä»¥åœ¨SIMDæ“ä½œæ—¶ï¼Œä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå°±èƒ½æ“ä½œ8ä¸ªFP32çš„è®¡ç®—
        * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/8ff99e17-45ca-4617-83a6-a048ec45b409)

      * [4] å›å½’å…¬å¼ï¼š
        * FLOPSåœ¨åŒç²¾åº¦çš„æ—¶å€™ï¼š
          * 3.0 * 10^9Hz * 8 core * 16 FLOPS/clk = 0.38 TFLOPS
            * 16 FLOPS/clk = 2 FMA * 4ä¸ª FP64 çš„ SIMD è¿ç®— * 2ä¹˜åŠ èåˆ
              * 2 FMAï¼š
                * ä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸç­‰äº2ä¸ªæµ®ç‚¹è¿ç®—
              * 4ä¸ª FP64 çš„ SIMD è¿ç®—ï¼š
                * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/c4a20d3f-f1cb-492b-a775-603071722901)

        * FLOPSåœ¨å•ç²¾åº¦çš„æ—¶å€™ï¼š
          * 3.0 * 10^9Hz * 8 core * 32 FLOPS/clk = 0.76 TFLOPS
            * 32 FLOPS/clk = 2 FMA * 8ä¸ª FP32çš„ SIMD è¿ç®— * 2ä¹˜åŠ èåˆ
              * 2 FMAï¼š
                * ä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸç­‰äº2ä¸ªæµ®ç‚¹è¿ç®—
              * 4ä¸ª FP64 çš„ SIMD è¿ç®—ï¼š
                * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/536399ae-621a-406b-92df-0fe294b543b7)




##### ï¼ˆ3ï¼‰FLOPS åœ¨ GPU ä¸­æ˜¯å¦‚ä½•è®¡ç®—çš„

* åŒºåˆ«ï¼š
  * GPU æ²¡æœ‰ AVX è¿™ä¸œè¥¿
  * ä½†æœ‰å¤§é‡çš„ Core æ¥æé«˜ååé‡
  * æœ‰ Tensor Core æ¥ä¼˜åŒ–çŸ©é˜µè¿ç®—
* ä¾‹å¦‚ï¼š
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/01429a08-3e03-4776-a789-cf655798c1c9)

  * ä¸€ä¸ªSMé‡Œé¢æœ‰ï¼š
    *  64ä¸ªå¤„ç†INT32çš„CUDA Core
    *  64ä¸ªå¤„ç†FP32çš„CUDA Core
    *  32ä¸ªå¤„ç†FP64çš„CUDA Core
    *  4ä¸ªå¤„ç†çŸ©é˜µè®¡ç®—çš„çš„Tensor Core
  * æ¯ä¸€ç§ç²¾åº¦åœ¨ä¸€ä¸ªSMä¸­çš„ååé‡ï¼ˆä¸€ä¸ªclkå¯ä»¥å®Œæˆçš„è®¡ç®—æ•°é‡ï¼‰
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/28098927-adc3-4a8b-8b00-166b8dcb3bb8)

* FP64çš„ååé‡ï¼ˆCUDA Coreï¼‰ï¼š
  * Throughput = 1.41GHz * 108 * 32 * 1 * 2 = 9.7 TFLOPS
    * é¢‘ç‡ï¼š1.41 GHz
    * SMæ•°é‡ï¼š108
    * ä¸€ä¸ªSMä¸­è®¡ç®—FP64çš„CUDA coreçš„æ•°é‡: 32
    * ä¸€ä¸ªCUDA coreä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„FP64: 1
    * ä¹˜åŠ : 2
* FP32çš„ååé‡ï¼ˆCUDA Coreï¼‰ï¼š
  * Throughput = 1.41GHz * 108 * 64 * 1 * 2 = 19.4 TFLOPS
    * é¢‘ç‡ï¼š1.41 GHz
    * SMæ•°é‡ï¼š108
    * ä¸€ä¸ªSMä¸­è®¡ç®—FP64çš„CUDA coreçš„æ•°é‡: 64
    * ä¸€ä¸ªCUDA coreä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„FP32: 1
    * ä¹˜åŠ : 2
* FP16çš„ååé‡ï¼ˆCUDA Coreï¼‰ï¼š
  * Ampereä¸­æ²¡æœ‰ä¸“é—¨é’ˆå¯¹ FP16 çš„CUDA coreï¼Œè€Œæ˜¯å°† FP32 çš„ CUDA  Core å’Œ FP64 çš„ CUDA Core ä¸€èµ·ä½¿ç”¨æ¥è®¡ç®— FP16ï¼›
  * Throughput = 1.41GHz * 108 * 256* 1 * 2 = 78 TFLOPS
    * é¢‘ç‡ï¼š1.41 GHz
    * SMæ•°é‡ï¼š108
    * ä¸€ä¸ªSMä¸­è®¡ç®— FP16 çš„CUDA coreçš„æ•°é‡: 256
      * **SMä¸­è®¡ç®—FP16çš„CUDA coreçš„æ•°é‡æ˜¯: 256 ( = 32 * 2 + 16 * 4 )**
    * ä¸€ä¸ªCUDA coreä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„FP32: 1
    * ä¹˜åŠ : 2
* INT8çš„ååé‡ï¼ˆCUDA Coreï¼‰ï¼š
  * Ampereä¸­æ²¡æœ‰ä¸“é—¨é’ˆå¯¹INT8çš„CUDA coreï¼Œè€Œæ˜¯ç”¨INT32çš„CUDA  Coreè®¡ç®—INT8ï¼›
  * Throughput = 1.41GHz * 108 * 256* 1 * 2 = 78 **TOPS**
    * é¢‘ç‡ï¼š1.41 GHz
    * SMæ•°é‡ï¼š108
    * ä¸€ä¸ªSMä¸­è®¡ç®— INT8 çš„CUDA coreçš„æ•°é‡: 256
      * **ä¸€ä¸ªSMä¸­è®¡ç®—INT8çš„CUDA coreçš„æ•°é‡æ˜¯: 256 ( = 64 * 4 )**
    * ä¸€ä¸ªCUDA coreä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„FP32: 1
    * ä¹˜åŠ : 2
* INT4çš„ååé‡ï¼š
  * Ampereä¸­æ²¡æœ‰ä¸“é—¨é’ˆå¯¹INT8çš„CUDA coreï¼Œè€Œæ˜¯ç”¨INT32çš„CUDA  Coreè®¡ç®—INT8ï¼›
  * Throughput = 1.41GHz * 108 * 256* 1 * 2 = 78 TFLOPS
    * é¢‘ç‡ï¼š1.41 GHz
    * SMæ•°é‡ï¼š108
    * ä¸€ä¸ªSMä¸­è®¡ç®— INT8 çš„CUDA coreçš„æ•°é‡: 256
      * **ä¸€ä¸ªSMä¸­è®¡ç®—INT8çš„CUDA coreçš„æ•°é‡æ˜¯: 256 ( = 64 * 4 )**
    * ä¸€ä¸ªCUDA coreä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„FP32: 1
    * ä¹˜åŠ : 2
* FP16çš„ååé‡ï¼ˆTensor Coreï¼‰ï¼š
  * Ampereæ¶æ„ä½¿ç”¨çš„æ˜¯ç¬¬ä¸‰ä»£Tensor Coreï¼Œå¯ä»¥ä¸€ä¸ªclkå®Œæˆä¸€ä¸ª 1024 ( = 256 * 4)ä¸ªFP16è¿ç®—ã€‚
    * å‡†ç¡®æ¥è¯´æ˜¯4x8çš„çŸ©é˜µä¸8x8çš„çŸ©é˜µçš„ FMA
      * 256 = 4 * 8 * 8
      * 4 = ä¸€ä¸ªSMä¸­è®¡ç®—FP16çš„Tensor coreçš„æ•°é‡4ä¸ª
  * Throughput = 1.41GHz * 108 * 4 * 256 * 2 = 312 TFLOPS
    * é¢‘ç‡ï¼š1.41 GHz
    * SMæ•°é‡ï¼š108
    * ä¸€ä¸ªSMä¸­è®¡ç®— FP16 çš„Tensor coreçš„æ•°é‡: 4
    * ä¸€ä¸ªTensor coreä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„FP16 : 256
    * ä¹˜åŠ : 2



##### ï¼ˆ4ï¼‰CUDA Core vs Tensor Core

* CUDA Core ï¼š
  * ä½¿ç”¨ä¸€ä¸ªCUDA Core è®¡ç®— C = A * Bï¼š
    * å¦‚æœä½¿ç”¨CUDA Coreçš„è¯ï¼Œ éœ€è¦8æ¬¡FMAï¼Œæ‰€ä»¥éœ€è¦8 ä¸ªclkæ‰å¯ä»¥å®Œæˆä¸€ä¸ªc(0,0)
      * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/f970e8b1-b695-4f76-9066-28dab8aa4341)

    * è¦å®Œæˆ4 x 8ä¸ 8x 4 çš„è®¡ç®—ï¼Œ éœ€è¦ 8 * 16 = 128ä¸ªclkæ‰ å¯ä»¥å®Œæˆ
      * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/cb18ec0e-d596-46ab-96b1-b0fab45c29bd)

    * å½“ç„¶ï¼Œå¦‚æœæˆ‘ä»¬æœ‰16ä¸ª CUDA coreçš„è¯ï¼Œè¿™äº›è®¡ ç®—å¹¶è¡Œï¼Œå®é™…ä¸Šæ˜¯8ä¸ªclkã€‚ ä¸ºäº†ä¸Tensor Coreæ¯”è¾ƒï¼Œ è¿™é‡Œåªç”¨ä¸€ä¸ªCUDA Core
* Tensor Core ï¼š
  * ä½¿ç”¨ä¸€ä¸ªTensor Core è®¡ç®— C = A * Bï¼š
    * ç¬¬ä¸€ä»£Tensor Coreï¼š
      * Tensor Coreä¸æ˜¯1ä¸ª1ä¸ªçš„ å¯¹FP16è¿›è¡Œå¤„ç†ï¼Œè€Œæ˜¯4x4 ä¸ªFP16ä¸€èµ·å¤„ç†ï¼Œç¬¬ä¸€ä¸ªclkå…ˆåšAå’ŒBçš„å‰åŠæ®µï¼Œ ç»“æœå…ˆå­˜ç€
        * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/e644b7d6-a45a-4386-afbf-2936f2132fd6)

      * ç¬¬äºŒä¸ªclkå†å¤„ç†Aå’ŒBçš„ååŠ æ®µï¼Œæœ€åå’Œå‰åŠæ®µç»“æœåšä¸ªç´¯ åŠ ï¼Œå®Œæˆè®¡ç®—ã€‚æ‰€ä»¥è¯´Tensor  Coreå¤„ç†4x8*8x4çš„è®¡ç®—åªéœ€ è¦1 + 1 = 2ä¸ªclk
        * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/d4ac7db0-68b4-482e-9134-15e624a26c18)

    * ç¬¬ä¸‰ä»£Tensor Coreï¼š
      * å¯ä»¥1clkå¤„ç† 4x8  * 8x8 çš„æ“ä½œï¼Œä¹Ÿå°±æ˜¯è¯´1clkå¯ä»¥å¤„ç† 256ä¸ªFP16
        * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/551a1115-de79-413a-8309-81e549d9eb8a)

  * FP16çš„ååé‡ï¼ˆTensor Coreï¼‰ï¼š
    * Ampereæ¶æ„ä½¿ç”¨çš„æ˜¯ç¬¬ä¸‰ä»£Tensor Coreï¼Œå¯ä»¥ä¸€ä¸ªclkå®Œæˆä¸€ä¸ª 1024 ( = 256 * 4)ä¸ªFP16è¿ç®—ã€‚
      * å‡†ç¡®æ¥è¯´æ˜¯4x8çš„çŸ©é˜µä¸8x8çš„çŸ©é˜µçš„ FMA
        * 256 = 4 * 8 * 8
        * 4 = ä¸€ä¸ªSMä¸­è®¡ç®—FP16çš„Tensor coreçš„æ•°é‡4ä¸ª
    * Throughput = 1.41GHz * 108 * 4 * 256 * 2 = 312 TFLOPS
      * é¢‘ç‡ï¼š1.41 GHz
      * SMæ•°é‡ï¼š108
      * ä¸€ä¸ªSMä¸­è®¡ç®— FP16 çš„Tensor coreçš„æ•°é‡: 4
      * ä¸€ä¸ªTensor coreä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„FP16 : 256
      * ä¹˜åŠ : 2
  * INT8çš„ååé‡ï¼ˆTensor Coreï¼‰ï¼š
    * Ampereæ¶æ„ä½¿ç”¨çš„æ˜¯ç¬¬ä¸‰ä»£Tensor Coreï¼Œå¯ä»¥ä¸€ä¸ªclkå®Œæˆä¸€ä¸ª 2048( = 256 * 2 * 4)ä¸ªINT8è¿ç®—ã€‚
      * å‡†ç¡®æ¥è¯´æ˜¯4x8çš„çŸ©é˜µä¸8x8çš„çŸ©é˜µçš„ FMA
        * 256 = 4 * 8 * 8
        * 4 * 2 = ä¸€ä¸ªSMä¸­è®¡ç®—INT8çš„Tensor coreçš„æ•°é‡4 * 2ä¸ª
    * Throughput = 1.41GHz * 108 * 4 * 512 * 2 = 624 TOPS
      * é¢‘ç‡ï¼š1.41 GHz
      * SMæ•°é‡ï¼š108
      * ä¸€ä¸ªSMä¸­è®¡ç®— INT8 çš„Tensor coreçš„æ•°é‡: 4
      * ä¸€ä¸ªTensor coreä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå¯ä»¥å¤„ç†çš„INT8: 512 
      * ä¹˜åŠ : 2



#### 4.1.2 Roofline model ä¸è®¡ç®—å¯†åº¦

Roofline model åœ¨æ¨¡å‹éƒ¨ç½²ä¸­çš„ä½œç”¨ä»…æ­¤äºé‡åŒ–ï¼Œèƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬åˆ†æåœ¨æ¨¡å‹éƒ¨ç½²æ—¶ç¡¬ä»¶æ€§èƒ½å¡åœ¨å“ªé‡Œäº†ï¼Œæœ‰æ²¡æœ‰ä¼˜åŒ–ç©ºé—´ã€‚éœ€è¦ç†è§£ç†è§£ä»€ä¹ˆå«åšRoofline model, memory bound, compute boundï¼Œ ä»¥åŠå„ä¸ªlayerçš„è®¡ç®—å¯†åº¦çš„åˆ†ç±»

##### ï¼ˆ1ï¼‰Roofline model ç®€ä»‹

ä¸€ä¸ªè¡¡é‡è®¡ç®—æœºè½¯ä»¶/ç¡¬ä»¶æ€§èƒ½çš„ä¸€ä¸ªåˆ†ææ¨¡å‹ã€‚æ˜¯David Pattersonå¸¦é¢†çš„UC  Berkerleyçš„å›¢é˜Ÿä¸2008å¹´å‘è¡¨çš„paperä¸­æå‡ºçš„æ¦‚å¿µã€‚

![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/4f492163-9224-491a-b5ec-667ac6ed6f88)


Roofline modelåœ¨æ¨¡å‹éƒ¨ç½²ä¸­çš„æ„ä¹‰ï¼š

* é’ˆå¯¹ä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éƒ¨ç½²çš„æ—¶å€™å¯ä»¥è¿›è¡Œé‡åŒ–ã€å‰ªæã€è’¸é¦ç­‰ä¼˜åŒ–æ–¹æ³•ï¼Œæå‡æ€§èƒ½
  * ä½†æ˜¯åœ¨æ¨¡å‹å·²ç»è®­ç»ƒå¥½ä¹‹åï¼Œå®ƒçš„å¾ˆå¤šæ¡†æ¶éƒ½æ˜¯å›ºå®šçš„ï¼Œé‚£ä¹ˆèƒ½å¤Ÿä¼˜åŒ–çš„åœ°æ–¹å°±å¾ˆå°‘äº†ï¼Œå­˜åœ¨å±€é™æ€§
  * å› æ­¤åœ¨æ¨¡å‹åˆ›å»ºåˆæœŸï¼Œæˆ‘ä»¬å°±è¦å°½å¯èƒ½åˆ›å»ºè®¡ç®—å¯†åº¦é«˜ï¼ŒåŒæ—¶ç²¾åº¦ä¹Ÿé«˜çš„ç®—å­ï¼Œé‚£ä¹ˆå†è¿›è¡Œé‡åŒ–å‰ªæçš„æ—¶å€™å°±éå¸¸ä¸é”™äº†
* **å¯ä»¥åœ¨ Roofline model ä¸­æ‰¾åˆ°çš„ä¼˜åŒ–æ–¹å‘**
  * åˆ†æ3x3 conv, 5x5 conv, 7x7 conv, 9x9 conv, 11x11 convçš„è®¡ç®—æ•ˆç‡
    * kernel sizeè¶Šå¤§ã€è®¡ç®—é‡å°±è¶Šå¤§ã€è®¡ç®—èµ„æºå ç”¨ç‡è¶Šå¤§
  * 1x1 convçš„è®¡ç®—æ•ˆç‡
    * èƒ½å¤Ÿé™ä½æ¨¡å‹è®¡ç®—é‡ï¼Œè®©æ¨¡å‹è½»é‡åŒ–ï¼Œä½†æ˜¯è½»é‡çš„æ¨¡å‹å¹¶ä¸ä¸€å®šä»£è¡¨å®ƒçš„è®¡ç®—æ•ˆç‡è¶Šé«˜ã€æ¨ç†æ—¶é—´è¶ŠçŸ­ï¼Œè¿™å’Œè®¡ç®—å¯†åº¦æœ‰å…³
  * depthwise convçš„è®¡ç®—æ•ˆç‡
    * èƒ½å¤Ÿé™ä½æ¨¡å‹è®¡ç®—é‡ï¼Œè®©æ¨¡å‹è½»é‡åŒ–ï¼Œä½†æ˜¯è½»é‡çš„æ¨¡å‹å¹¶ä¸ä¸€å®šä»£è¡¨å®ƒçš„è®¡ç®—æ•ˆç‡è¶Šé«˜ã€æ¨ç†æ—¶é—´è¶ŠçŸ­ï¼Œè¿™å’Œè®¡ç®—å¯†åº¦æœ‰å…³
  * åˆ†æç›®å‰è®¡ç®—çš„ç“¶é¢ˆï¼ˆbottleneckï¼‰
    * åˆ†ææ€§èƒ½å¡åœ¨å“ªé‡Œï¼šmemoryï¼Ÿç¡¬ä»¶è®¡ç®—å³°å€¼ï¼Ÿ
  * åˆ†ææ¨¡å‹çš„å¯ä»¥ä¼˜åŒ–çš„ä¸Šé™
    * æˆ‘ä»¬ä¸çŸ¥é“æ¨¡å‹ç“¶é¢ˆåœ¨å“ªï¼Œå°±ä¸èƒ½åˆ†æå‡ºä¼˜åŒ–ä»å“ªæ–¹é¢åˆ‡å…¥



##### ï¼ˆ2ï¼‰å…³é”®å‚æ•°

* è®¡ç®—é‡ï¼ˆFLOPsï¼‰
  * å•ä½æ˜¯FLOPsï¼ˆå°å†™ï¼‰ï¼Œè¡¨ç¤ºæ¨¡å‹ä¸­æœ‰å¤šå°‘ä¸ªæµ®ç‚¹è¿ç®—ï¼ˆfloating point operationsï¼‰ã€‚ æ˜¯è¡¡é‡**æ¨¡å‹å¤§å°**çš„æ ‡å‡†
* è®¡ç®—å³°å€¼ï¼ˆFLOPSï¼‰
  * å•ä½æ˜¯FLOPS (ä¹Ÿå¯ä»¥æ˜¯FLOP/s)ï¼Œ è¡¨ç¤ºè®¡ç®—æœºæ¯ç§’å¯ä»¥æ‰§è¡Œçš„æµ®ç‚¹è¿ç®—å¤šå°‘ï¼ˆfloating point operationsï¼‰ã€‚æ˜¯è¡¡é‡**è®¡ç®—æœºæ€§èƒ½**çš„æ ‡å‡†
* å‚æ•°é‡ï¼ˆByteï¼‰
  * å•ä½æ˜¯Byteï¼Œè¡¨ç¤ºæ¨¡å‹ä¸­æ‰€æœ‰çš„weights(ä¸»è¦åœ¨convå’ŒFCä¸­) çš„é‡ã€‚æ˜¯è¡¡é‡**æ¨¡å‹å¤§å°**çš„æ ‡å‡†
* è®¿å­˜é‡ï¼ˆByteï¼‰
  * å•ä½æ˜¯Byteï¼Œè¡¨ç¤ºæ¨¡å‹ä¸­æŸä¸€ä¸ªç®—å­ï¼Œæˆ–è€…æŸä¸€å±‚layerè¿›è¡Œè®¡ç®—æ—¶éœ€è¦ä¸memoryäº§ç”Ÿ read/write çš„é‡ã€‚æ˜¯åˆ†ææ¨¡å‹ä¸­æŸäº›è®¡ç®—çš„**è®¡ç®—æ•ˆç‡**çš„æ ‡å‡†ä¹‹ä¸€
  * è®¡ç®—æ–¹æ³•ï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/309ece6d-3714-4ca3-a9a7-65920944815d)

    * æ‰€éœ€è¦çš„è®¿å­˜é‡ =  ï¼ˆ kernel size * kernel num + output size * output numï¼‰ * 4 = 288 Byte = 0.288 KB
      * 4ï¼šä¸€èˆ¬éƒ½æ˜¯ç”¨FP32æ¥è®¡ç®—ï¼ŒFP32æ—¶32bitï¼Œ1Byte = 8bitï¼Œæ‰€ä»¥32bitå°±æ˜¯4ä¸ªByte
  * é™·é˜±ï¼š
    * å‚æ•°é‡å’Œè®¿å­˜é‡çš„å•ä½éƒ½æ˜¯ byteï¼Œä½†ä¸ä¸€æ ·ã€‚convçš„**å‚æ•°é‡**å°±æ˜¯ weight çš„å¤§å°ï¼Œ**è·Ÿinput/ouputæ— å…³**ã€‚ transformerçš„**å‚æ•°**ä¼šæ ¹æ®**è¾“å…¥ tensor å¤§å°æ”¹å˜**è€Œæ”¹å˜ï¼ˆCNNä¸Transformerçš„åŒºåˆ«ï¼‰
* å¸¦å®½
  * å•ä½æ˜¯Byte/sï¼Œå…¨ç§°æ˜¯ memory bandwidthï¼Œ è¡¨ç¤ºçš„æ˜¯**å•ä½æ—¶é—´å†…å¯ä»¥ä¼ è¾“çš„æ•°æ®é‡**çš„å¤šå°‘ã€‚æ˜¯è¡¡é‡è®¡ç®—æœº**ç¡¬ä»¶memoryæ€§èƒ½**çš„ä¸€ ä¸ªæ ‡å‡†ã€‚
    * å½±å“å› ç´ 
      * memory clock (GHz)
        * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/2a3b8f22-8c8e-47e3-b16b-42bb39c6c0ce)

      * memory bus width (Byte)
        * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/8ec93ecf-dda5-4991-a39e-21bf4dd7f864)

      * memory channel
        * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/cfdb1998-0ea5-4530-b467-e80d6fba704b)

  * è®¡ç®—æ–¹æ³•
    * Intel Xeon Gold 6000 (server)
      * => memory bandwidth = 2666 MHz * 8 Bytes * 6 = 128GB/s
        * memory: DDR4-2666
        * memory clock: 2666 MHz
        * memory bus width: 8 Bytes
        * memory channel: 6
    *  NVIDIA Quadro RTX 6000
      * => memory bindwidth = 14 Gbps * 48 Bytes * 1 = 672GB/s
        * memory: GDDR6
        * memory clock: 1750 MHz
        * memory clock effective: 1750 MHz * 8  = 14Gbps
        * memory interface width: 48 Bytes (384 bits)



##### ï¼ˆ3ï¼‰è®¡ç®—å¯†åº¦ï¼ˆOperational intensityï¼‰

* å•ä½æ˜¯FLOPs/Byteï¼Œè¡¨ç¤ºçš„æ˜¯ä¼ é€å•ä½æ•°æ®å¯ä»¥è¿›è¡Œçš„æµ®ç‚¹è¿ç®—æ•°ã€‚
  * è®¡ç®—å¯†åº¦ = è®¡ç®—é‡ / è®¿å­˜é‡
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/0e9b79c0-ad0a-450e-ae7e-516223f874c8)

* æˆ‘ä»¬å¯ä»¥é€šè¿‡æé«˜è®¡ç®—å¯†åº¦ï¼Œè®©æˆ‘ä»¬çš„ç¡¬ä»¶å°½é‡å¤„äºé¥±å’ŒçŠ¶æ€ï¼Œä»è€Œæé«˜è®¡ç®—æ•ˆç‡
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/ef6d036a-8dc6-4954-ad61-8e3eb45defb1)




##### ï¼ˆ4ï¼‰ç¡¬ä»¶æ€§èƒ½åˆ†æï¼ˆRTX 3080ï¼‰

* ä»¥3080ä¸ºä¾‹
  * ç¡¬ä»¶èµ„æº
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/191a3dc2-7b36-4657-81e9-c6643623530f)

  * åˆ†æè®¡ç®—å¯†åº¦
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/ef70418f-7c03-4742-90dc-b82265f4d789)

  * æ€»ç»“
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/7132a3ab-ba10-424d-a010-b3cca2959ea4)

  * ç›®å‰æˆ‘ä»¬å•ç‹¬åˆ†æäº†å‡ ä¸ªlayerå¯¹è®¡ç®—å¯†åº¦çš„å½±å“ã€ï¼ˆ5ï¼‰è®¡ç®—å¯†åº¦çš„å½±å“å› ç´ ï¼ˆFP32çš„Convä¸ºä¾‹ï¼‰ã€‘ã€‚ä½†DNNæ˜¯ä¸€ä¸ªå¤šä¸ªlayerçš„ç»„åˆï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿéœ€è¦å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œåˆ†æï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/176b9a42-3acd-45fb-8663-579c5acb0456)

  * RTX 3080 Ampereæ¶æ„ä¸­FP32çš„è®¡ç®—åœ¨39.2FLOPs/byteæ‰è¾¾åˆ°è®¡ç®—é¥±å’Œï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/4e3b5b25-f9dc-40fc-896e-c683f8972b10)

  * æ‰€ä»¥è¿™äº›æ¨¡å‹å…¶ç†è®ºä¸Šéƒ½æ²¡æœ‰è®¡ç®—é¥±å’Œï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/6ca4e65e-5d8a-4835-9dba-fa4f33f1feb4)


##### ï¼ˆ5ï¼‰è®¡ç®—å¯†åº¦çš„å½±å“å› ç´ ï¼ˆFP32çš„Convä¸ºä¾‹ï¼‰

* 1ã€**kernel size** çš„å½±å“
  * è®¡ç®—å…¬å¼ï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/e5241fb2-873a-4199-80b9-f0734fce8226)

  *  **group convolution** å¯¹è®¡ç®—å¯†åº¦çš„å½±å“ï¼š
    * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/166a4f34-53d6-4dae-a613-5081662fd04b)

      * elementwise conv(1x1 conv)çš„è™½ç„¶è¾ƒå°‘äº†è®¡ç®—é‡ï¼Œä½†æ˜¯è®¡ç®—å¯†åº¦ä¹Ÿå¾ˆä½ã€‚éšç€kernel sizeå¢å¤§ï¼Œè®¡ç®—å¯†åº¦å¢é•¿ç‡é€æ¸ä¸‹é™
* 2ã€**output size** çš„å½±å“
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/e9424c65-cca9-4455-a2c8-28df038ceadd)

    * éšç€output sizeå˜å¤§ï¼Œè®¡ç®—å¯†åº¦çš„å¢é•¿ç‡é€æ¸ä¸‹é™
* 3ã€**channel size** çš„å½±å“
  * ![image](https://github.com/CoderSuHang/TensorRT-Learning-Note/assets/104765251/53b96629-0801-4082-80b3-e9e508aaa19a)

    * è¶Šå¤§çš„ channel size è®¡ç®—å¯†åº¦è¶Šé«˜ã€‚
* 4ã€**group convolution** çš„å½±å“
  * groupï¼šå¯¹è¾“å…¥è¾“å‡ºåˆ†ç»„åšå·ç§¯çš„å¤šå°‘ç»„
  * ![image-20240521213017823](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521213017823.png)
    * depthwiseè™½ç„¶é™ä½äº†è®¡ç®—é‡ï¼Œä½†è®¡ç®—å¯†åº¦ä¹Ÿä¸‹é™çš„å¾ˆå¤š
* 5ã€**tensor reshape** çš„å½±å“
  * reshape çŸ©é˜µè½¬ç½®çš„æœ¬è´¨å¹¶æ²¡æœ‰è®¡ç®—ï¼Œåªæ˜¯å¯¹æ•°æ®è¿›è¡Œäº†æ‹·è´å’Œç§»åŠ¨
    * æ¨¡å‹ä¸­æ²¡æœ‰tensor reshape
      * ![image-20240521213118429](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521213118429.png)
    * æ¨¡å‹ä¸­æœ‰3ä¸ªtensor reshape
      * ![image-20240521213629674](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521213629674.png)
    * æ¨¡å‹ä¸­æœ‰5ä¸ªtensor reshape
      * ![image-20240521213642931](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521213642931.png)
  * **tensor reshape** è¶Šå¤šï¼Œè®¡ç®—å¯†åº¦è¶Šå°
* 6ã€**FC** çš„å½±å“
  * è®¡ç®—å…¬å¼ï¼š
    * ![image-20240521213831477](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521213831477.png)
  * **FC** å¯¹è®¡ç®—å¯†åº¦çš„å½±å“ï¼š
    * ![image-20240521213843917](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521213843917.png)
      * FCçš„è®¡ç®—å¯†åº¦éå¸¸ä½çš„åŸå› åœ¨äºå®ƒçš„å¤§é‡çš„è®¿å­˜



##### ï¼ˆ6ï¼‰ç¡¬ä»¶æ€§èƒ½åˆ†æï¼ˆJetsonï¼‰

* ä»¥Jetson Xavier AGX Voltaä¸ºä¾‹
  * ç¡¬ä»¶èµ„æº
    * ![image-20240521214633820](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521214633820.png)
  * åˆ†æè®¡ç®—å¯†åº¦
    * ![image-20240521214718079](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521214718079.png)
  * æ€»ç»“
    * ![image-20240521214726732](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521214726732.png)
  * ç›®å‰æˆ‘ä»¬å•ç‹¬åˆ†æäº†å‡ ä¸ªlayerå¯¹è®¡ç®—å¯†åº¦çš„å½±å“ã€ï¼ˆ5ï¼‰è®¡ç®—å¯†åº¦çš„å½±å“å› ç´ ï¼ˆFP32çš„Convä¸ºä¾‹ï¼‰ã€‘ã€‚ä½†DNNæ˜¯ä¸€ä¸ªå¤šä¸ªlayerçš„ç»„åˆï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿéœ€è¦å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œåˆ†æï¼š
    * ![image-20240521214119053](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521214119053.png)
  * Jetson AGX Xavieræ¶æ„ä¸­FP32çš„è®¡ç®—åœ¨10.2FLOPs/byteå°±è®¡ç®—é¥±å’Œï¼š
    * ![image-20240521214748433](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521214748433.png)
  * æ‰€ä»¥è¿™äº›æ¨¡å‹å…¶å®éƒ½ç†è®ºä¸Šå·²ç»è®¡ç®—é¥±å’Œï¼š
    * ![image-20240521214324082](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521214324082.png)



##### ï¼ˆ7ï¼‰é™¤äº†ç†è®ºä¸Šï¼Œå®é™…ä¸ŠRooflineå½±å“å› ç´ è¿˜æœ‰å¾ˆå¤š

* **ã€é‡ç‚¹ã€‘**åˆ°ç›®å‰è®²çš„æ˜¯ç†è®ºå€¼ã€‚ç„¶è€Œå®é™…ä¸Šæˆ‘ä»¬ä¼šå‘ç°
  * å³°å€¼å¯èƒ½ä¼šå°äº22.4TOPS
  * bandwidthå¯èƒ½ä¼šå°äº137GB/s
  * ![image-20240521215116489](C:\Users\10482\AppData\Roaming\Typora\typora-user-images\image-20240521215116489.png)
* **éœ€è¦æ ¹æ®ä¸€ç³»åˆ— benchmark æ‰¾åˆ°éƒ¨ç½²æ¶æ„çš„çœŸå®å€¼ã€‚**
  * æ¯”å¦‚è‡ªå·±å†™å‡ ä¸ªè®¡ç®—å¯†é›†çš„æ ¸å‡½æ•°ï¼ˆå‡å°‘ä½œä¸ºmemory cuppy æ•°æ®ä¼ è¾“ç”¨çš„ç®—å­ï¼‰



### 4.2 æ¨¡å‹éƒ¨ç½²çš„å‡ å¤§è¯¯åŒº

#### 4.2.1 FLOPs å¹¶ä¸èƒ½è¡¡é‡æ¨¡å‹æ€§èƒ½

* å› ä¸ºFLOPsåªæ˜¯æ¨¡å‹è®¡ç®—å¤§å°çš„å•ä½
* è¿˜éœ€è¦è€ƒè™‘
  * è®¿å­˜é‡
    * æ¯”å¦‚ä¸€ä¸ªæ ¸å‡½æ•°è®¡ç®—è¿‡äºå¤æ‚ï¼Œè¿™ä¸ªæ ¸å‡½æ•°éƒ½åœ¨åšreshapeè¿™ç§å†…å­˜è®¿é—®çš„äº‹æƒ…ï¼Œè€Œè®¡ç®—éƒ¨åˆ†å ç”¨çš„å¹¶ä¸å¤š
  * è·Ÿè®¡ç®—æ— å…³çš„DNNéƒ¨åˆ†
    * (reshape, shortcut, nchw2nhwcç­‰ç­‰) 
  * DNNä»¥å¤–çš„éƒ¨åˆ†
    * (å‰å¤„ç†ã€åå¤„ç†è¿™äº›)
      * å‰å¤„ç†ï¼šbiliner resizeã€ä»¿å°„å˜æ¢ã€clopå±…ä¸­ç­‰
      * åå¤„ç†ï¼šYOLO headéƒ¨çš„NMSï¼ŒTensor Decodeç­‰



#### 4.2.2 TensorRT å¹¶ä¸èƒ½å®Œå…¨ä¾é 

* TensorRTå¯ä»¥å¯¹æ¨¡å‹åšé€‚å½“çš„ä¼˜åŒ–ï¼Œä½†æ˜¯æœ‰ä¸Šé™
* æ¯”å¦‚
  * <u>è®¡ç®—å¯†åº¦ä½çš„**1x1 conv**ï¼Œ **depthwise conv**ä¸ä¼šé‡æ„</u>
    * å†æ€ä¹ˆä¼˜åŒ–è®¡ç®—å¯†åº¦è¿˜æ˜¯å¾ˆå·®ï¼Œä¸ä¼šå¥½çš„
  * <u>GPUæ— æ³•ä¼˜åŒ–çš„åœ°æ–¹ä¼šåˆ°CPUæ‰§è¡Œ</u>
    * ä¸æ˜¯ç»å¯¹ï¼Œå¯ä»¥æ‰‹åŠ¨ä¿®æ”¹ä»£ç å®ç°éƒ¨åˆ†ï¼ˆæ¯”å¦‚å‰å¤„ç†å’Œåå¤„ç†ï¼‰ï¼Œè®©éƒ¨åˆ†cpuæ‰§è¡Œè½¬åˆ°gpuæ‰§è¡Œ
  * <u>æœ‰äº›å†—é•¿çš„è®¡ç®—ï¼ŒTensorRTå¯èƒ½ä¸èƒ½ä¼˜åŒ–ï¼Œå¯èƒ½ä¸ºäº†ä¼˜åŒ–æ·»åŠ ä¸€äº›å¤šä½™çš„æ“ä½œ</u>
    * æ¯”å¦‚ç±»ä¼¼äºé‡åŒ–çš„æ—¶å€™æ·»åŠ **reformatter**è¿™ç§ç®—å­ï¼ˆTensorRTä¸ºäº†è¾¾åˆ°Tensoré‡åŒ–å½¢çŠ¶åŒ¹é…æ—¶æ·»åŠ ï¼‰
    * ç›´æ¥ä¿®æ”¹ä»£ç å®ç°éƒ¨åˆ†
  * <u>å­˜åœ¨TensorRTå°šæœªæ”¯æŒçš„ç®—å­ï¼ˆæˆ–è€…æ•ˆç‡ä¸é«˜ï¼‰</u>
    * å¯ä»¥è‡ªå·±å†™pluginï¼Œå¯ä»¥ç”¨ cuBLASã€catlaså†™ä¸€ä¸ªé«˜æ•ˆçš„plugin
  * <u>TensorRTä¸ä¸€å®šä¼šåˆ†é…Tensor Core</u>
    * trtexec æ¨ç†å¼•æ“åˆ›å»ºçš„æ—¶å€™
    * å› ä¸ºTensorRT kernel auto tuningä¼šé€‰æ‹©æœ€åˆé€‚çš„kernel



#### 4.2.3 CUDA Core ä¸ Tensor Core çš„åŒºåˆ«

* æœ‰çš„æ—¶å€™TensorRTå¹¶ä¸ä¼šåˆ†é…Tensor Core
  * kernel auto tuningè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è§£
  * ğŸ“Œã€é¢è¯•ã€‘æ‰€ä»¥æœ‰æ—¶ä¼šå‡ºç°ç±»ä¼¼äº**INT8çš„é€Ÿåº¦æ¯”FP16åè€Œæ…¢**äº†
    * FP16é‡åŒ–çš„æ—¶å€™ï¼ŒTensorRTä¼šæ‰¾ä¸€äº›èƒ½å¤Ÿåœ¨Tensor Coreä¸Šè·‘çš„ä¸€äº›Kernelæ ¸å‡½æ•°
    * ä½†å½“æˆ‘ä»¬ç»™å®ƒè®¾å®šæˆINT8çš„æ—¶å€™ï¼Œæ¯”å¦‚æœ‰ä¸€äº›ç®—å­ä¸æ”¯æŒINT8ï¼Œæˆ–è€…æœ‰äº›è®¡ç®—åœ¨è½¬ä¸ºINT8çš„æ—¶å€™ä¼šæ·»åŠ å¤šä½™çš„æ“ä½œï¼ˆä¾‹å¦‚åœ¨QATçš„æ—¶å€™ä¼šQDQï¼ŒQDQåšèåˆä¼šæ·»åŠ å¾ˆå¤šå…¶ä»–æ“ä½œï¼Œè®©æ¨¡å‹å˜å¾—å¤æ‚ï¼ŒTensorRTè§‰å¾—æ·»åŠ é‚£ä¹ˆå¤šæ“ä½œåå†Tensor Coreä¸Šæ‰§è¡Œæ•ˆç‡å¹¶ä¸æ˜¯é‚£ä¹ˆé«˜ï¼Œé‚£å°±è‡ªåŠ¨fullbackåˆ°CUDA Coreä¸Šå»æ‰§è¡Œï¼‰
    * è¿™æ—¶å°±ä¼šå‡ºç°FP16åœ¨CUDA Coreä¸Šï¼Œè€ŒINT8å°±è·‘åˆ°CUDA Coreä¸Šçš„ç°è±¡
  * **ä½¿ç”¨Tensor Coreéœ€è¦è®©tensor sizeä¸º8æˆ–è€…16çš„å€æ•°**ï¼ˆè®°ä½å°±å¥½ï¼‰
    * 8çš„å€æ•°ï¼šfp16ç²¾åº¦
    * 16çš„å€æ•°ï¼šint8ç²¾åº¦



#### 4.2.4 ä¸èƒ½å¿½è§† å‰å¤„ç†/åå¤„ç† çš„overhead

* å¯¹äºä¸€äº›è½»é‡çš„æ¨¡å‹ï¼Œç›¸æ¯”äºDNNæ¨ç†éƒ¨åˆ†ï¼ˆå‡ æ¯«ç§’ï¼‰ï¼Œå‰å¤„ç†/åå¤„ç†å¯èƒ½ä¼šæ›´è€—æ—¶é—´
  * å› ä¸ºæœ‰äº›å‰å¤„ç†/åå¤„ç†çš„å¤æ‚é€»è¾‘ä¸é€‚åˆGPUå¹¶è¡Œ
* ç„¶è€Œæœ‰å¾ˆå¤šç§è§£å†³åŠæ³•
  * å¯ä»¥æŠŠå‰å¤„ç†/åå¤„ç†ä¸­å¯å¹¶è¡Œçš„åœ°æ–¹æ‹¿å‡ºæ¥è®©GPUå¹¶è¡Œåšï¼Œä¸ç”¨openCVåš
    * æ¯”å¦‚RGB2BGR, Normalization, resize, crop, NCHW2NHWC
  * å¯ä»¥åœ¨CPUä¸Šä½¿ç”¨ä¸€äº›é’ˆå¯¹å›¾åƒå¤„ç†çš„ä¼˜åŒ–åº“
    * GPUåœ¨å¿™çš„æ—¶å€™ï¼Œæ¯”å¦‚è§†é¢‘æ¨ç†çš„æ—¶å€™ï¼Œé’ˆå¯¹æ¯å¸§çš„overlapingï¼Œå‰ä¸€å¸§DNNéƒ¨åˆ†æ¨ç†è®¡ç®—å®Œä¹‹åç›´æ¥è®©åä¸€å¸§å¼€å§‹æ¨ç†è®¡ç®—ï¼Œè€Œè®©CPUå»åšç¬¬ä¸€å¸§çš„åå¤„ç†ã€‚è®©å‰å¤„ç†-DNN-åå¤„ç†å®ç°é‡å æ“ä½œ
    * æ¯”å¦‚Halideï¼Œä½¿ç”¨Halideè¿›è¡Œblur, resize, crop, DBSCAN, sobelè¿™äº›ä¼šæ¯” CPUå¿«
* å¹¶ä¸æ˜¯èƒ½GPUåŠ é€Ÿçš„åœ°æ–¹å°±GPUåŠ é€Ÿ
  * éœ€è¦è€ƒè™‘GPUå ç”¨ç‡



#### 4.2.5 å¯¹ä½¿ç”¨TensorRTå¾—åˆ°çš„æ¨ç†å¼•æ“åšbenchmarkå’Œprofiling

* ä½¿ç”¨TensorRTå¾—åˆ°æ¨ç†å¼•æ“å¹¶å®ç°inferåªæ˜¯ä¼˜åŒ–çš„ç¬¬ä¸€æ­¥
* éœ€è¦ä½¿ç”¨NVIDIAæä¾›çš„benchmark toolsè¿›è¡Œprofiling
  * åˆ†ææ¨¡å‹ç“¶é¢ˆåœ¨å“ªé‡Œ
  * åˆ†ææ¨¡å‹å¯è¿›ä¸€æ­¥ä¼˜åŒ–çš„åœ°æ–¹åœ¨å“ªé‡Œ
    * æ¯”å¦‚æé«˜è®¿å­˜æ•ˆç‡ï¼ˆå¸¦å®½ï¼‰æˆ–è€…è®¡ç®—é‡ï¼Ÿ
  * åˆ†ææ¨¡å‹ä¸­å¤šä½™çš„memory accessåœ¨å“ªé‡Œ
    * æ¯”å¦‚reformate
  * å¯ä»¥ä½¿ç”¨ï¼š
    * nsys, nvprof, dlprof, Nsightè¿™äº›å·¥å…·



### 4.3 æ¨¡å‹éƒ¨ç½²ä¼˜åŒ–-é‡åŒ–

#### 4.3.1 ç†è§£é‡åŒ–è¯ç”Ÿçš„èƒŒæ™¯ä¸æ„ä¹‰

#### 4.3.2 é‡åŒ–çš„åŸºæœ¬ç®—æ³•ä¸å¯¹ç§°/éå¯¹ç§°é‡åŒ–

#### 4.3.3 é‡åŒ–ç²’åº¦ä¸ç²¾åº¦/æ•ˆç‡çš„å…³ç³»

#### 4.3.4 é‡åŒ–æ ¡å‡†ç®—æ³•æ¯”è¾ƒ

#### 4.3.5 PTQ é‡åŒ–ä»¥åŠ layer-wise æ•æ„Ÿåº¦åˆ†æ

#### 4.3.6 QAT é‡åŒ–ä»¥åŠ Q/DQ èŠ‚ç‚¹ä¸ç®—å­çš„èåˆ

#### 4.3.7 å¸¸è§çš„é‡åŒ–æŠ€å·§ä¸æ­£ç¡®çš„é‡åŒ–æ€è·¯



### 4.4 æ¨¡å‹éƒ¨ç½²ä¼˜åŒ–-å‰ªæ

#### 4.4.1 Channel purning ç®—æ³•ä¸ L1-Norm çš„å…³ç³»

#### 4.4.2 Fine-grained structured sparse pruning

#### 4.4.3 åˆ†æ Sparse Tensor Core ç¡¬ä»¶å±‚é¢å¤„ç†å‰ªæ
